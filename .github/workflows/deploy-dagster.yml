name: Deploy Dagster

on:
  workflow_call:
    inputs:
      # Stack & Repository Configuration
      stack_name:
        description: "CloudFormation stack name"
        required: true
        type: string
      environment:
        description: "Environment to deploy to (prod or staging)"
        required: true
        type: string

      # GHA Runner Configuration
      runner_config:
        description: "GitHub Actions runner configuration (JSON array)"
        required: false
        type: string
        default: '["ubuntu-latest"]'

      # AWS Configuration
      aws_region:
        description: "AWS region for deployment"
        required: true
        type: string
      vpc_id:
        description: "VPC ID for ECS tasks"
        required: true
        type: string
      subnet_ids:
        description: "Private subnet IDs for ECS tasks (comma-separated)"
        required: true
        type: string

      # Container & Application Configuration
      ecr_repository_url:
        description: "Full ECR repository URL"
        required: true
        type: string
      ecr_image_tag:
        description: "Docker image tag"
        required: true
        type: string

      # Fargate Configuration
      daemon_cpu:
        description: "CPU units for Dagster daemon"
        required: false
        type: string
        default: "512"
      daemon_memory:
        description: "Memory in MiB for Dagster daemon"
        required: false
        type: string
        default: "1024"
      webserver_cpu:
        description: "CPU units for Dagster webserver"
        required: false
        type: string
        default: "512"
      webserver_memory:
        description: "Memory in MiB for Dagster webserver"
        required: false
        type: string
        default: "1024"
      # Run Job Configuration (for EcsRunLauncher)
      run_job_cpu:
        description: "CPU units for Dagster run jobs"
        required: false
        type: string
        default: "1024"
      run_job_memory:
        description: "Memory in MiB for Dagster run jobs"
        required: false
        type: string
        default: "4096"
      max_concurrent_runs:
        description: "Maximum concurrent Dagster runs (QueuedRunCoordinator)"
        required: false
        type: string
        default: "20"

      # Cache Configuration
      valkey_url:
        description: "Valkey ElastiCache endpoint URL"
        required: true
        type: string
      valkey_sg_id:
        description: "Security group ID for Valkey access"
        required: true
        type: string

      # Database Configuration
      database_sg_id:
        description: "Security group ID for PostgreSQL access"
        required: true
        type: string

      # Bastion Access (for port forwarding to Dagster UI)
      bastion_sg_id:
        description: "Security group ID for bastion host access (optional)"
        required: false
        type: string
        default: ""

      # API Access (for Dagster job submission)
      api_sg_id:
        description: "Security group ID for API service to submit Dagster jobs (optional)"
        required: false
        type: string
        default: ""

      # Monitoring Configuration
      container_insights_enabled:
        description: "Enable Container Insights for ECS cluster (enabled/disabled)"
        required: false
        type: string
        default: "disabled"

      # S3 Bucket Configuration (from S3 stack outputs)
      shared_raw_bucket_arn:
        description: "ARN of shared raw data bucket (from S3 stack)"
        required: true
        type: string
      shared_processed_bucket_arn:
        description: "ARN of shared processed data bucket (from S3 stack)"
        required: true
        type: string
      deployment_bucket_arn:
        description: "ARN of deployment bucket (from S3 stack)"
        required: true
        type: string
      user_data_bucket_arn:
        description: "ARN of user data bucket (from S3 stack)"
        required: true
        type: string
      public_data_bucket_arn:
        description: "ARN of public data bucket (from S3 stack)"
        required: true
        type: string
      logs_bucket_arn:
        description: "ARN of logs bucket for Dagster compute logs (from S3 stack)"
        required: true
        type: string
      public_data_cdn_url:
        description: "CloudFront CDN URL for public data (from S3 stack)"
        required: true
        type: string

    secrets:
      ACTIONS_TOKEN:
        description: "GitHub token for checkout (optional - falls back to github.token)"
        required: false

jobs:
  deploy:
    runs-on: ${{ fromJSON(inputs.runner_config) }}
    timeout-minutes: 30
    permissions:
      id-token: write
      contents: read
    outputs:
      is_new_stack: ${{ steps.deploy-stack.outputs.is_new_stack }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository }}
          ref: ${{ github.ref }}
          token: ${{ secrets.ACTIONS_TOKEN || github.token }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ vars.AWS_ROLE_ARN }}
          aws-region: ${{ inputs.aws_region }}

      - name: Deploy Dagster CloudFormation Stack
        id: deploy-stack
        run: |
          if aws cloudformation describe-stacks --stack-name ${{ inputs.stack_name }} 2>&1 | grep -q 'Stack with id ${{ inputs.stack_name }} does not exist'; then
            STACK_ACTION="create-stack"
            echo "Creating new stack ${{ inputs.stack_name }}"
            echo "is_new_stack=true" >> $GITHUB_OUTPUT
          else
            STACK_ACTION="update-stack"
            echo "Updating existing stack ${{ inputs.stack_name }}"
            echo "is_new_stack=false" >> $GITHUB_OUTPUT
          fi

          STACK_PARAMS="ParameterKey=Environment,ParameterValue=${{ inputs.environment }} \
                ParameterKey=VpcId,ParameterValue=${{ inputs.vpc_id }} \
                ParameterKey=SubnetIds,ParameterValue=\"${{ inputs.subnet_ids }}\" \
                ParameterKey=ECRRepositoryUrl,ParameterValue=${{ inputs.ecr_repository_url }} \
                ParameterKey=ECRImageTag,ParameterValue=${{ inputs.ecr_image_tag }} \
                ParameterKey=DaemonCpu,ParameterValue=${{ inputs.daemon_cpu }} \
                ParameterKey=DaemonMemory,ParameterValue=${{ inputs.daemon_memory }} \
                ParameterKey=WebserverCpu,ParameterValue=${{ inputs.webserver_cpu }} \
                ParameterKey=WebserverMemory,ParameterValue=${{ inputs.webserver_memory }} \
                ParameterKey=RunJobCpu,ParameterValue=${{ inputs.run_job_cpu }} \
                ParameterKey=RunJobMemory,ParameterValue=${{ inputs.run_job_memory }} \
                ParameterKey=MaxConcurrentRuns,ParameterValue=${{ inputs.max_concurrent_runs }} \
                ParameterKey=ValkeyUrl,ParameterValue=${{ inputs.valkey_url }} \
                ParameterKey=ValkeyClientSecurityGroupId,ParameterValue=${{ inputs.valkey_sg_id }} \
                ParameterKey=DatabaseSecurityGroupId,ParameterValue=${{ inputs.database_sg_id }} \
                ParameterKey=BastionSecurityGroupId,ParameterValue=${{ inputs.bastion_sg_id }} \
                ParameterKey=ApiSecurityGroupId,ParameterValue=${{ inputs.api_sg_id }} \
                ParameterKey=ContainerInsightsEnabled,ParameterValue=${{ inputs.container_insights_enabled }} \
                ParameterKey=SharedRawBucketArn,ParameterValue=\"${{ inputs.shared_raw_bucket_arn }}\" \
                ParameterKey=SharedProcessedBucketArn,ParameterValue=\"${{ inputs.shared_processed_bucket_arn }}\" \
                ParameterKey=DeploymentBucketArn,ParameterValue=\"${{ inputs.deployment_bucket_arn }}\" \
                ParameterKey=UserDataBucketArn,ParameterValue=\"${{ inputs.user_data_bucket_arn }}\" \
                ParameterKey=PublicDataBucketArn,ParameterValue=\"${{ inputs.public_data_bucket_arn }}\" \
                ParameterKey=LogsBucketArn,ParameterValue=\"${{ inputs.logs_bucket_arn }}\" \
                ParameterKey=PublicDataCDNURL,ParameterValue=\"${{ inputs.public_data_cdn_url }}\""

          # Deploy or update the stack
          if [ "$STACK_ACTION" = "create-stack" ]; then
            aws cloudformation $STACK_ACTION \
              --stack-name ${{ inputs.stack_name }} \
              --template-body file://cloudformation/dagster.yaml \
              --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \
              --parameters $STACK_PARAMS \
              --tags \
                Key=Environment,Value=${{ inputs.environment }} \
                Key=Service,Value=RoboSystems \
                Key=Component,Value=Dagster \
                Key=Repository,Value=${{ github.repository }} \
                Key=CreatedBy,Value=GitHubActions
          else
            UPDATE_OUTPUT=$(aws cloudformation $STACK_ACTION \
              --stack-name ${{ inputs.stack_name }} \
              --template-body file://cloudformation/dagster.yaml \
              --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM \
              --parameters $STACK_PARAMS \
              --tags \
                Key=Environment,Value=${{ inputs.environment }} \
                Key=Service,Value=RoboSystems \
                Key=Component,Value=Dagster \
                Key=Repository,Value=${{ github.repository }} \
                Key=CreatedBy,Value=GitHubActions 2>&1) || true

            if echo "$UPDATE_OUTPUT" | grep -q "No updates are to be performed"; then
              echo "Stack is already up to date - no changes needed"
            elif echo "$UPDATE_OUTPUT" | grep -q "error"; then
              echo "Error updating stack: $UPDATE_OUTPUT"
              exit 1
            else
              echo "Stack update initiated successfully"
            fi
          fi

      - name: Monitor Stack Deployment
        uses: ./.github/actions/monitor-stack-deployment
        with:
          stack-name: ${{ inputs.stack_name }}
          timeout: "1800"
          interval: "10"
